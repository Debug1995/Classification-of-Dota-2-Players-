{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "def build_model(name, class_num):\n",
    "    \n",
    "    path = '/home/kevinxing/Documents/BigData/Dota2_Player_Classification/'\n",
    "    \n",
    "    \n",
    "    file_name = path + name + \".csv\"\n",
    "    svm_file = name + \"_svm.txt\"\n",
    "    model_name = name + \".model\"\n",
    "    \n",
    "    X = []\n",
    "    Y = []\n",
    "    f = open(file_name, \"r\")\n",
    "    for line in f:\n",
    "        line = line.strip('\\r\\n')\n",
    "        line = line.split(',')\n",
    "        x_tmp = []\n",
    "        for i in range(len(line)):\n",
    "            if i != len(line) - 1 :\n",
    "                x_tmp.append(float(line[i]))\n",
    "            else:\n",
    "                #print x_tmp\n",
    "                X.append(x_tmp)\n",
    "                Y.append(int(float(line[i])))\n",
    "                \n",
    "    fsvm = open(svm_file, 'w')\n",
    "    dump_svmlight_file(X, Y, fsvm, zero_based=False)\n",
    "    fsvm.close()\n",
    "    \n",
    "    # $example off$\n",
    "    #from pyspark import SparkContext\n",
    "    #sc = SparkContext(appName=\"MultiClassMetricsExample\")\n",
    "\n",
    "    # Several of the methods available in scala are currently missing from pyspark\n",
    "    # $example on$\n",
    "    # Load training data in LIBSVM format\n",
    "    data = MLUtils.loadLibSVMFile(sc, svm_file)\n",
    "\n",
    "    # Split data into training (60%) and test (40%)\n",
    "    training, test = data.randomSplit([0.6, 0.4], seed=11)\n",
    "    training.cache()\n",
    "\n",
    "    # Run training algorithm to build the model\n",
    "    model = LogisticRegressionWithLBFGS.train(training, numClasses=class_num)\n",
    "\n",
    "    # Compute raw scores on the test set\n",
    "    predictionAndLabels = test.map(lambda lp: (float(model.predict(lp.features)), lp.label))\n",
    "\n",
    "    # Instantiate metrics object\n",
    "    metrics = MulticlassMetrics(predictionAndLabels)\n",
    "\n",
    "    # Overall statistics\n",
    "    precision = metrics.precision()\n",
    "    recall = metrics.recall()\n",
    "    f1Score = metrics.fMeasure()\n",
    "    print(name + \"Summary Stats\")\n",
    "    print(\"Precision = %s\" % precision)\n",
    "    print(\"Recall = %s\" % recall)\n",
    "    print(\"F1 Score = %s\" % f1Score)\n",
    "\n",
    "    # Statistics by class\n",
    "    labels = data.map(lambda lp: lp.label).distinct().collect()\n",
    "    for label in sorted(labels):\n",
    "        print(\"Class %s precision = %s\" % (label, metrics.precision(label)))\n",
    "        print(\"Class %s recall = %s\" % (label, metrics.recall(label)))\n",
    "        print(\"Class %s F1 Measure = %s\" % (label, metrics.fMeasure(label, beta=1.0)))\n",
    "\n",
    "    # Weighted stats\n",
    "    print(\"Weighted recall = %s\" % metrics.weightedRecall)\n",
    "    print(\"Weighted precision = %s\" % metrics.weightedPrecision)\n",
    "    print(\"Weighted F(1) Score = %s\" % metrics.weightedFMeasure())\n",
    "    print(\"Weighted F(0.5) Score = %s\" % metrics.weightedFMeasure(beta=0.5))\n",
    "    print(\"Weighted false positive rate = %s\" % metrics.weightedFalsePositiveRate)\n",
    "    \n",
    "    model.save(sc, model_name)\n",
    "\n",
    "#print a,\n",
    "#print raw_data\n",
    "#sc = SparkContext('local')\n",
    "#spark = SparkSession(sc)\n",
    "#labels = ['pregnant_times', 'plasma_glucose', 'blood_pressure', 'skin_fold', 'serum_insulin', 'body_mass', 'diabates', 'age']\n",
    "#data = spark.createDataFrame(raw_data, labels)\n",
    "#data.show()\n",
    "#print X\n",
    "#print Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create svm file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10_players_modelSummary Stats\n",
      "Precision = 0.293603703462\n",
      "Recall = 0.293603703462\n",
      "F1 Score = 0.293603703462\n",
      "Class 0.0 precision = 0.303317535545\n",
      "Class 0.0 recall = 0.0139646519747\n",
      "Class 0.0 F1 Measure = 0.0267000417188\n",
      "Class 1.0 precision = 0.4537299339\n",
      "Class 1.0 recall = 0.211720643314\n",
      "Class 1.0 F1 Measure = 0.288718642031\n",
      "Class 2.0 precision = 0.305234110735\n",
      "Class 2.0 recall = 0.795407098121\n",
      "Class 2.0 F1 Measure = 0.441170794468\n",
      "Class 3.0 precision = 0.0276211950395\n",
      "Class 3.0 recall = 0.0257352941176\n",
      "Class 3.0 F1 Measure = 0.0266449157151\n",
      "Weighted recall = 0.293603703462\n",
      "Weighted precision = 0.314144842023\n",
      "Weighted F(1) Score = 0.220739350711\n",
      "Weighted F(0.5) Score = 0.228152546011\n",
      "Weighted false positive rate = 0.250709906909\n"
     ]
    }
   ],
   "source": [
    "#build_model(\"1_players_model\", 4)\n",
    "#build_model(\"2_players_model\", 5)\n",
    "#build_model(\"3_players_model\", 4)\n",
    "#build_model(\"4_players_model\", 5)\n",
    "#build_model(\"5_players_model\", 5)\n",
    "#build_model(\"6_players_model\", 4)\n",
    "#build_model(\"7_players_model\", 4)\n",
    "#build_model(\"8_players_model\", 5)\n",
    "#build_model(\"9_players_model\", 5)\n",
    "#build_model(\"10_players_model\", 4)\n",
    "\n",
    "\n",
    "\n",
    "#print Y\n",
    "#fsvm = open('players_info_kda.txt', 'w')\n",
    "#dump_svmlight_file(X, Y, fsvm, zero_based=False)\n",
    "#fsvm.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/pyspark/mllib/evaluation.py:237: UserWarning: Deprecated in 2.0.0. Use accuracy.\n",
      "  warnings.warn(\"Deprecated in 2.0.0. Use accuracy.\")\n",
      "/usr/local/lib/python2.7/dist-packages/pyspark/mllib/evaluation.py:249: UserWarning: Deprecated in 2.0.0. Use accuracy.\n",
      "  warnings.warn(\"Deprecated in 2.0.0. Use accuracy.\")\n",
      "/usr/local/lib/python2.7/dist-packages/pyspark/mllib/evaluation.py:262: UserWarning: Deprecated in 2.0.0. Use accuracy.\n",
      "  warnings.warn(\"Deprecated in 2.0.0. Use accuracy.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Stats\n",
      "Precision = 0.557831561093\n",
      "Recall = 0.557831561093\n",
      "F1 Score = 0.557831561093\n",
      "Class 0.0 precision = 0.559681697613\n",
      "Class 0.0 recall = 0.691803278689\n",
      "Class 0.0 F1 Measure = 0.618768328446\n",
      "Class 1.0 precision = 0.428186714542\n",
      "Class 1.0 recall = 0.20902716915\n",
      "Class 1.0 F1 Measure = 0.280918727915\n",
      "Class 2.0 precision = 0.512494705633\n",
      "Class 2.0 recall = 0.643617021277\n",
      "Class 2.0 F1 Measure = 0.57062013676\n",
      "Class 3.0 precision = 0.575163398693\n",
      "Class 3.0 recall = 0.59620596206\n",
      "Class 3.0 F1 Measure = 0.585495675316\n",
      "Class 4.0 precision = 0.586552217454\n",
      "Class 4.0 recall = 0.793036750484\n",
      "Class 4.0 F1 Measure = 0.674342105263\n",
      "Class 5.0 precision = 0.675287356322\n",
      "Class 5.0 recall = 0.714285714286\n",
      "Class 5.0 F1 Measure = 0.69423929099\n",
      "Class 6.0 precision = 0.384615384615\n",
      "Class 6.0 recall = 0.320600272851\n",
      "Class 6.0 F1 Measure = 0.349702380952\n",
      "Class 7.0 precision = 0.477021524142\n",
      "Class 7.0 recall = 0.339123242349\n",
      "Class 7.0 F1 Measure = 0.396422528402\n",
      "Class 8.0 precision = 0.626674786845\n",
      "Class 8.0 recall = 0.744573082489\n",
      "Class 8.0 F1 Measure = 0.680555555556\n",
      "Weighted recall = 0.557831561093\n",
      "Weighted precision = 0.540687569397\n",
      "Weighted F(1) Score = 0.537433737426\n",
      "Weighted F(0.5) Score = 0.535665228837\n",
      "Weighted false positive rate = 0.0618798722178\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Licensed to the Apache Software Foundation (ASF) under one or more\n",
    "# contributor license agreements.  See the NOTICE file distributed with\n",
    "# this work for additional information regarding copyright ownership.\n",
    "# The ASF licenses this file to You under the Apache License, Version 2.0\n",
    "# (the \"License\"); you may not use this file except in compliance with\n",
    "# the License.  You may obtain a copy of the License at\n",
    "#\n",
    "#    http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "#\n",
    "\n",
    "# $example on$\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "# $example off$\n",
    "\n",
    "from pyspark import SparkContext\n",
    "\n",
    "\n",
    "#sc = SparkContext(appName=\"MultiClassMetricsExample\")\n",
    "\n",
    "    # Several of the methods available in scala are currently missing from pyspark\n",
    "    # $example on$\n",
    "    # Load training data in LIBSVM format\n",
    "data = MLUtils.loadLibSVMFile(sc, \"players_info_kda.txt\")\n",
    "\n",
    "    # Split data into training (60%) and test (40%)\n",
    "training, test = data.randomSplit([0.7, 0.3], seed=11)\n",
    "training.cache()\n",
    "\n",
    "    # Run training algorithm to build the model\n",
    "model = LogisticRegressionWithLBFGS.train(training, numClasses=9)\n",
    "\n",
    "    # Compute raw scores on the test set\n",
    "predictionAndLabels = test.map(lambda lp: (float(model.predict(lp.features)), lp.label))\n",
    "\n",
    "    # Instantiate metrics object\n",
    "metrics = MulticlassMetrics(predictionAndLabels)\n",
    "\n",
    "    # Overall statistics\n",
    "precision = metrics.precision()\n",
    "recall = metrics.recall()\n",
    "f1Score = metrics.fMeasure()\n",
    "print(\"Summary Stats\")\n",
    "print(\"Precision = %s\" % precision)\n",
    "print(\"Recall = %s\" % recall)\n",
    "print(\"F1 Score = %s\" % f1Score)\n",
    "\n",
    "    # Statistics by class\n",
    "labels = data.map(lambda lp: lp.label).distinct().collect()\n",
    "for label in sorted(labels):\n",
    "    print(\"Class %s precision = %s\" % (label, metrics.precision(label)))\n",
    "    print(\"Class %s recall = %s\" % (label, metrics.recall(label)))\n",
    "    print(\"Class %s F1 Measure = %s\" % (label, metrics.fMeasure(label, beta=1.0)))\n",
    "\n",
    "    # Weighted stats\n",
    "print(\"Weighted recall = %s\" % metrics.weightedRecall)\n",
    "print(\"Weighted precision = %s\" % metrics.weightedPrecision)\n",
    "print(\"Weighted F(1) Score = %s\" % metrics.weightedFMeasure())\n",
    "print(\"Weighted F(0.5) Score = %s\" % metrics.weightedFMeasure(beta=0.5))\n",
    "print(\"Weighted false positive rate = %s\" % metrics.weightedFalsePositiveRate)\n",
    "    # $example off$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.mllib.classification.LogisticRegressionModel'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print type(model)\n",
    "model.predict([0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(sc, \"test_model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = LogisticRegressionModel.load(sc, \"test_model.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.predict([0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
